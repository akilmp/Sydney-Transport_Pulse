# Sydney Transport Pulse â€“ Project Documentation

## Table of Contents

1. [Project Overview](#project-overview)
2. [Solution Architecture](#solution-architecture)
3. [Tech Stack & Services](#tech-stack--services)
4. [Data Sources](#data-sources)
5. [Repository Structure](#repository-structure)
6. [Local Development Environment](#local-development-environment)
7. [Cloud Deployment (AWS reference)](#cloud-deployment-aws-reference)
8. [Data Pipeline Details](#data-pipeline-details)
9. [Data Quality & Testing](#data-quality--testing)
10. [CI/CD Workflow](#cicd-workflow)
11. [Observability & Alerting](#observability--alerting)
12. [Visualisation Layer](#visualisation-layer)
13. [Security & Compliance](#security--compliance)
14. [Costâ€‘Management Guidelines](#cost-management-guidelines)
15. [Demo Recording Guide](#demo-recording-guide)
16. [Troubleshooting & FAQ](#troubleshooting--faq)
17. [Stretch Goals](#stretch-goals)
18. [References & Further Reading](#references--further-reading)

---

## Project Overview

**Sydney Transport Pulse** is a realâ€‘time dataâ€‘lakehouse that ingests live GTFSâ€‘Realtime GPS pings from Transport for NSW (TfNSW), enriches them with static timetable data, and surfaces live onâ€‘timeâ€‘performance dashboards.
The project is designed to showcase *every core competency* sought in 2025 junior dataâ€‘engineering roles:

| Competency                       | Demonstrated By                                        |
| -------------------------------- | ------------------------------------------------------ |
| Cloud object storage & lakehouse | Iceberg tables on S3 (or MinIO for local)              |
| Streaming ingestion              | Kafka â†’ Spark Structured Streaming                     |
| Batch ELT & modelling            | dbt transformation from **bronze â†’ silver â†’ gold**     |
| Orchestration                    | Apache Airflow DAGs                                    |
| IaC & CI/CD                      | Terraform modules + GitHub Actions pipeline            |
| Data quality                     | Great Expectations tests & Airflow failâ€‘fast gates     |
| Observability                    | Prometheus metrics + Grafana dashboards + Slack alerts |
| Visualisation                    | Apache Superset interactive dashboards                 |

> **Elevator pitch (30â€¯s):** â€œHow late is the 891 bus to UNSW?  My pipeline streams every vehicle GPS ping (\~3â€¯M/day), builds Iceberg fact tables in nearâ€‘realâ€‘time, validates data quality, and publishes an onâ€‘timeâ€‘performance dashboard â€“ all infra defined in Terraform, tested in GitHub Actions, and monitored in Grafana.â€

---

## Solution Architecture

```
+------------------+        +------------------+        +------------------+
|  TfNSW API       |  -->   |  Kafka Topic     |  -->   |  Spark Structured |
|  (GTFSâ€‘Realtime) |  1     |  bus_positions   |  2     |  Streaming Job    |
+------------------+        +------------------+        +------------------+
         |                                                         |
         |3                                                        |4
         v                                                         v
+------------------+                                       +------------------+
|  Iceberg Bronze  |  --(Airflow)-->  Iceberg Silver  -->  |  Iceberg Gold    |
|  (Raw JSON)      |                    (Clean)           |  (fact/dim)       |
+------------------+                                       +------------------+
         |                                                         |
         |5                                                        |6
         v                                                         v
+------------------+                                       +------------------+
| Great Expectations|                                     | Superset / Snowfl|
| Validation        |                                     |  queries & charts |
+------------------+                                       +------------------+
         |                                                         |
         +-----------+--------------------+-------------------------+
                     |                    |
               Prometheus <â€‘â€‘ metrics â€‘â€‘> Grafana  (alerts to Slack)
```

**Legend:**

1. Python `producer.py` polls the TfNSW VehiclePosition gRPC endpoint every 10â€¯s.
2. Raw JSON pushed to Kafka topic **`bus_positions`**.
3. Spark Structured Streaming writes each microâ€‘batch to Iceberg *bronze* table on S3.
4. Hourly Airflow DAG triggers Spark batch job to cleanse/join GTFS static â†’ *silver* table.
5. Airflow task runs Great Expectations; fails pipeline if <95â€¯% rows pass.
6. dbt **`run`** and **`test`** create starâ€‘schema (*gold*) in Snowflake, queried by Superset.


---

## Tech Stack & Services

| Layer               | Local Dev (Docker Compose) | Cloud (AWS reference)                                                         |
| ------------------- | -------------------------- | ----------------------------------------------------------------------------- |
| Object Storage      | MinIO                      | Amazon S3                                                                     |
| Streaming           | Kafka + Zookeeper          | Amazon MSK (Kafka)                                                            |
| Compute (Streaming) | Spark 3.5 / PySpark        | EMR Serverless or Glue 4.0                                                    |
| Compute (Batch)     | Spark on Docker            | AWS Glue Jobs                                                                 |
| Orchestration       | Apache Airflow 2.9         | MWAA (Managed Airflow)                                                        |
| Lakehouse Format    | Apache Iceberg 1.5         | Iceberg on S3                                                                 |
| Modelling           | dbt Core 1.8               | dbt Core on EC2 (CI) or dbt Cloud                                             |
| Data Quality        | Great Expectations 0.18    | Same                                                                          |
| Monitoring          | Prometheus + Grafana       | Prometheus OSS on EC2 / Amazon Managed Service for Prometheus + Grafana Cloud |
| CI/CD               | GitHub Actions             | GitHub Actions (selfâ€‘hosted runner optional)                                  |
| IaC                 | Terraform 1.7              | Terraform + S3 backend + AWS IAM                                              |
| BI / Viz            | Superset 4.0               | Superset on ECS Fargate                                                       |

---

## Data Sources

| Feed                                | Format          | Frequency      | Endpoint                                                   |
| ----------------------------------- | --------------- | -------------- | ---------------------------------------------------------- |
| **GTFSâ€‘Realtime Vehicle Positions** | Protobuf / gRPC | Every 10â€¯s     | `https://api.transport.nsw.gov.au/v1/gtfs/vehiclepos`      |
| **GTFS Static Timetables**          | Zip (CSV)       | Daily snapshot | `https://api.transport.nsw.gov.au/v1/gtfs/schedule/{date}` |

API access requires registering an app key with [TfNSW Open Data](https://opendata.transport.nsw.gov.au/).  Store the key as `TFNSW_API_KEY`.

---

## Repository Structure

```
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ ingest/
â”‚   â”œâ”€â”€ producer.py            # GTFSâ€‘Realtime â†’ Kafka
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ spark_jobs/
â”‚   â”œâ”€â”€ bronze_stream.py       # Structured Streaming
â”‚   â””â”€â”€ silver_batch.py        # Batch cleanse & join
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/pipeline.py       # DAG definition (bronzeâ†’silverâ†’dbtâ†’quality)
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ dim_route.sql
â”‚   â”‚   â””â”€â”€ fact_trip_punctuality.sql
â”‚   â””â”€â”€ tests/
â”œâ”€â”€ great_expectations/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/dashboards/
â”œâ”€â”€ iac/
â”‚   â””â”€â”€ terraform/*            # S3, MSK, EMR, MWAA modules
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ ci.yml                 # lint + unit tests
â”‚   â””â”€â”€ deploy.yml             # Terraform plan/apply + dbt docs
â””â”€â”€ docs/
    â””â”€â”€ demo_script.md
```

---

## Local Development Environment

1. **Clone repo & copy env file**

   ```bash
   git clone https://github.com/<yourâ€‘user>/sydneyâ€‘transportâ€‘pulse.git
   cd sydneyâ€‘transportâ€‘pulse
   cp .env.example .env   # add TFNSW_API_KEY & AWS creds (localstack optional)
   ```
2. **Launch stack**

   Start all services (Kafka, Spark, Airflow, MinIO, Prometheus, Grafana and Superset) with Docker Compose:

   ```bash
   docker compose up -d
   # Wait about 30s for Airflow on http://localhost:8080 and Superset on http://localhost:8088
   ```
3. **Seed GTFS static** (daily job)

   ```bash
   make fetch_gtfs_static          # downloads & pushes to MinIO s3://stp/gtfs_static/
   # DATE=20240101 make fetch_gtfs_static  # optional override
   ```
4. **Start streaming**

   Launch the Python producer which polls the TfNSW API and publishes messages to the `bus_positions` topic:

   ```bash
   python ingest/producer.py   # or docker exec kafka-producer
   ```
5. **Trigger DAG manually**

   1. Open Airflow â†’ `pipeline_gtfs_bus` DAG â†’ *Trigger Run*.
   2. Watch tasks: `bronze_stream`, `silver_batch`, `dbt_run`, `ge_validate`.
6. **Explore data**

   ```sql
   -- inside Superset SQL Lab
   SELECT route_id, COUNT(*) AS trips, AVG(delay_min) AS avg_delay
   FROM fact_trip_punctuality
   WHERE service_date = CURRENT_DATE
   GROUP BY route_id
   ORDER BY avg_delay DESC;
   ```

### Environment variables

| Name                                          | Purpose                 | Example                                |
| --------------------------------------------- | ----------------------- | -------------------------------------- |
| `TFNSW_API_KEY`                               | Auth token for GTFS API | `abcd1234xyz`                          |
| `AWS_ACCESS_KEY_ID` / `AWS_SECRET_ACCESS_KEY` | Terraform + EMR         | `AKIAâ€¦`                                |
| `MINIO_ROOT_USER` / `MINIO_ROOT_PASSWORD`     | Local S3 creds          | `minioadmin`                           |
| `SLACK_WEBHOOK_URL`                           | Alert channel           | `https://hooks.slack.com/services/...` |

---

## Cloud Deployment (AWS reference)

> **Goal:** replicate local topology using managed AWS services via Terraform.

### Highâ€‘level steps

1. `cd iac/terraform && terraform init`
2. `terraform plan â€‘var-file="prod.tfvars"`
3. `terraform apply` (creates S3 bucket `stpâ€‘lakeâ€‘prod`, MSK cluster, EMR Serverless workspace, MWAA env, IAM roles).
4. Push Airflow DAG & plugins to MWAA S3 bucket.
5. Trigger MWAA DAG to start streaming job on EMR Serverless.
6. Set GitHub Secrets (`AWS_ACCESS_KEY_ID`, etc.) so `deploy.yml` can run Terraform from CI.

### Terraform stateâ€‘management

* **Backend:** S3 bucket `stpâ€‘tfstate` + DynamoDB table for locks.
* Use `AWS_PROFILE=stpâ€‘prod` or `AWS_ROLE` in CI for leastâ€‘privilege.

### Networking

| Service        | VPC                   | Public/Private           |
| -------------- | --------------------- | ------------------------ |
| MSK brokers    | `vpcâ€‘stp`             | Private subnets with NAT |
| EMR Serverless | same VPC              | Private                  |
| MWAA           | same VPC              | Private + ALB            |
| Superset (ECS) | Public subnet via ALB | Public URL (optional)    |

See `iac/terraform/README.md` for full variable docs.

---

## Data Pipeline Details

### Bronze Layer â€“ Raw

* Spark Structured Streaming microâ€‘batches (trigger once/10â€¯s).
* Schema evolves via Icebergâ€™s **schemaâ€‘onâ€‘read**; partitioned by `service_date`.

### Silver Layer â€“ Cleansed

* Batch job every 15â€¯min.
* Deduplicates on `(trip_id, timestamp)`, validates geo boundaries, joins to timetable (`route_id`).
* Columns: `route_id`, `trip_id`, `vehicle_id`, `event_time`, `delay_sec`, â€¦

### Gold Layer â€“ Analytics

* dbt incremental models (partition by `service_date`).
* `fact_trip_punctuality` (one row per stop arrival).
* `dim_route` (route metadata).
* Materialised in Snowflake for interactive BI.

### Orchestration

```
bronze_stream (SparkStreaming, alwaysâ€‘on)
   â†“ hourly trigger
silver_batch  ->  dbt_run  ->  ge_validate  ->  superset_refresh
```

* DAG retries 2Ã—, exponential backâ€‘off.
* Failure alerts via Slack webhook.

---

## Data Quality & Testing

| Tool                                                  | Tests                            |
| ----------------------------------------------------- | -------------------------------- |
| **Great Expectations**                                | â€¢ Null & range checks on lat/lon |
| â€¢ `delay_sec >= 0`                                    |                                  |
| â€¢ Row count vs expectation (â‰¥90â€¯% of scheduled trips) |                                  |
| **dbt tests**                                         | â€¢ `not_null` on PKs              |
| â€¢ `unique` on `dim_route.route_id`                    |                                  |
| â€¢ Custom SQL test: punctuality in \[â€‘10, +120]â€¯min    |                                  |

Failing any GE checkpoint marks Airflow task **failed**, halting DAG.

### Running validations locally

Execute the checkpoint using the Great Expectations CLI:

```bash
great_expectations -c great_expectations/great_expectations.yml checkpoint run stp_bus
```

---

## CI/CD Workflow

```yaml
name: CI
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
      - run: pip install -r ingest/requirements.txt
      - run: flake8 ingest spark_jobs
      - name: dbt run & test
        run: |
          cd dbt && dbt deps && dbt run -m +fact_trip_punctuality && dbt test
  terraform:
    if: github.ref == 'refs/heads/main'
    needs: test
    runs-on: ubuntu-latest
    environment: prod
    steps:
      - uses: hashicorp/setup-terraform@v3
      - run: terraform fmt -check
      - run: terraform init
      - run: terraform plan -out=tfplan
      - run: terraform apply -input=false tfplan
```

* **Secrets:** stored in GitHub â†’ *Settings â†’ Secrets â†’ Actions* (AWS creds, Slack webhook, TFNSW key).
* **dbt Docs Publish:** postâ€deploy step uploads site to S3 and invalidates CloudFront.

---

## Observability & Alerting

* **Prometheus exporters**

  * Spark (JMX) â†’ scrape `/metrics` via `jmx_prometheus_javaagent`.
  * Airflow metrics exported via builtâ€‘in `/admin/metrics` (2.9+).
  * Custom exporter for Kafka consumer lag.
* **Grafana dashboards**

  * *Pipeline Health* â€“ DAG duration, task success ratio.
  * *Bus Delay Heatmap* â€“ realâ€‘time average delay by route/hour.
  * *Infrastructure* â€“ MSK broker CPU, EMR cost.
* **Alerts**

  * Slack alert if `ge_validate` fails.
  * PagerDuty webhook on consumer lag > 2â€¯min.

---

## Visualisation Layer

* Superset on `http://localhost:8088` (admin/admin).
* Key charts:

  1. **Map** â€“ realâ€‘time vehicle positions (point geo, autoâ€‘refresh 15â€¯s).
  2. **Delay by Hour** â€“ heatmap of average delay minutes across hours Ã— routes.
  3. **Onâ€‘time % trend** â€“ line chart by day.
* Dashboards exported under `superset/`.
  To import the JSON files:
  1. Log in as an admin user.
  2. Go to **Settings â†’ Import Dashboards**.
  3. Upload any file from `superset/` and confirm.

---

## Security & Compliance

| Concern             | Mitigation                                                         |
| ------------------- | ------------------------------------------------------------------ |
| API key leakage     | `.env` not committed; secrets in GitHub + SSM Parameter Store      |
| Data privacy        | Only public GPS data, no personal information.                     |
| IAM least privilege | Terraform IAM roles: EMR runtime role limited to S3 bucket prefix. |
| Network ingress     | MSK/Airflow in private subnets; Superset public but readâ€‘only.     |
| Credential rotation | Use AWS Secrets Manager rotation for Slack/webhooks.               |

---

## Costâ€‘Management Guidelines

* **MSK tier:** use `kafka.t3.small` brokers (â‰ˆAUD 0.13/hr each) for test env.
* **EMR Serverless:** configure preâ€‘initialised workers = 0, scaling between 0â€“4.
* **S3 lifecycle:** move bronze to Glacier after 30â€¯days.
* **Grafana Cloud free tier** or use OSS on EC2 t4g.micro.

Typical monthly devâ€‘env cost < **AUDâ€¯50** when idle (\~10â€¯GB storage, low MSK usage).

---

## Demo Recording Guide

1. **Prep**

   * `docker compose up` + trigger pipeline 5â€¯min before recording so Superset has data.
   * OBS Studio â†’ 1440p window capture; enable mic + webcam corner (PiP).
2. **Run order**

   1. Architecture diagram (ASCII in README).
   2. Terminal split view (`watch -n1 "kcat -C -t bus_positions -o -5"` + Spark logs).
   3. Airflow UI â†’ DAG run.
   4. Great Expectations validation result green.
   5. Superset dashboard animation.
   6. GitHub Actions run badge green.
3. **Narration tips**

   * Hook viewer with relatable pain (â€œmissed the 891 againâ€).
   * Highlight each buzzword once: *streaming*, *lakehouse*, *data quality*, *IaC*, *observability*.
4. **Publish**

   * Title: â€œðŸš Realâ€‘time Lakehouse on AWS: Sydney Transport Pulse (Dataâ€‘Engineering Demo)â€.
   * Description: link repo + timestamps + tech stack hashtags (#Spark #dbt #Iceberg).

---

## Troubleshooting & FAQ

| Issue                                     | Fix                                                                                               |
| ----------------------------------------- | ------------------------------------------------------------------------------------------------- |
| `producer.py` 403                         | TfNSW API key invalid â†’ regenerate key, export `TFNSW_API_KEY`.                                   |
| Spark job exits w/ *NoClassDefFoundError* | Ensure `--packages` includes `org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.5.0`.           |
| Airflow cannot reach MinIO                | Update `.env`: `MINIO_ENDPOINT=http://minio:9000` and add network `airflow` in compose overrides. |
| Superset blank map tiles                  | Under *Settings â†’ Mapbox API* add your token or switch to OpenStreet basemap plugin.              |

---

## Stretch Goals

* **Streaming ML:** PyFlink job for anomaly detection on delay spikes.
* **Athena Iceberg query:** expose data to analysts without Snowflake licence.
* **OpenTelemetry trace export:** unify Spark + Airflow + Superset traces.
* **Autoscaling demo:** Karpenter on EKS for Spark pods.

---

## References & Further Reading

* TfNSW Open Data docs â€“ [https://opendata.transport.nsw.gov.au/](https://opendata.transport.nsw.gov.au/)
* Iceberg quickâ€‘start â€“ [https://iceberg.apache.org/docs/latest/](https://iceberg.apache.org/docs/latest/)
* Great Expectations deployment patterns â€“ [https://docs.greatexpectations.io/](https://docs.greatexpectations.io/)
* AWS EMR Serverless best practices â€“ 2025 whiteâ€‘paper
* dbt â€œDefinitive Guide to Star Schemasâ€ â€“ dbt Labs 2023

---

*Last updated: 25â€¯Julyâ€¯2025*

## License

This project is licensed under the [MIT License](LICENSE).
